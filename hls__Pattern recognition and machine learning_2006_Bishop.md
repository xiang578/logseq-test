---
public: true
file: [Pattern recognition and machine learning_2006_Bishop.pdf](file:///Users/xry/Dropbox/zotero-lib/Pattern recognition and machine learning_2006_Bishop.pdf)
file-path: file:///Users/xry/Documents/syncthing/zotero-lib/Pattern recognition and machine learning_2006_Bishop.pdf
title: hls__Pattern recognition and machine learning_2006_Bishop
tags:
date: 2024-10-05
lastMod: 2024-10-05
toc: "true"
---

One role for the distributions discussed in this chapter is to model the probability distribution p(x) of a random variable x, given a ﬁnite set x1, . . . , xN of observations.
ls-type:: annotation
hl-page:: 87
hl-color:: yellow
[[density estimation]] 定义
sufﬁcient statistic
ls-type:: annotation
hl-page:: 89
hl-color:: yellow
[[充分统计量]]
discrete random variables
ls-type:: annotation
hl-page:: 88
hl-color:: purple
离散随机变量
parametric distribution
ls-type:: annotation
hl-page:: 88
hl-color:: purple
参数分布
criterion
ls-type:: annotation
hl-page:: 88
hl-color:: purple
标准
in a Bayesian treatment we introduce prior distributions over the parameters and then use Bayes’ theorem to compute the corresponding posterior distribution given the observed data.
ls-type:: annotation
hl-page:: 88
hl-color:: yellow
[[贝叶斯方法]] 流程
conjugate prior
ls-type:: annotation
hl-page:: 88
hl-color:: purple
共轭先验
One limitation of the parametric approach is that it assumes a speciﬁc functional form for the distribution, which may turn out to be inappropriate for a particular application.
ls-type:: annotation
hl-page:: 88
hl-color:: purple
参数化方法的一个限制是需要先假设分布的特定函数形式
calculus
ls-type:: annotation
hl-page:: 91
hl-color:: purple
[[微积分]]
In fact, we might wonder whether it is a general property of Bayesian learning that, as we observe more and more data, the uncertainty represented by the posterior distribution will steadily decrease.
ls-type:: annotation
hl-page:: 94
hl-color:: yellow
They can be used, for example, in real-time learning scenarios where a steady stream of data is arriving, and predictions must be made before all of the data is seen. Because they do not require the whole data set to be stored or loaded into memory, sequential methods are also useful for large data sets. Maximum likelihood methods can also be cast into a sequential framework.
ls-type:: annotation
hl-page:: 93
hl-color:: yellow
[[Bayesian Online Learning]]