---
alias:
- Gradient Descend
public: true
title: 梯度下降法
tags:
date: 2024-10-05
updated: 2024-10-05
toc: true
mathjax: true
---

在机器学习任务中，需要最小化损失函数 ${L(\theta )}$ 来，其中 ${\theta}$ 是模型的参数。梯度下降法常用来求解无约束的最优化问题，它在选定的初始值 ${\theta_0}$ 基础上不断迭代得到新的 ${\theta}$ 值，最终实现极小化损失函数。

迭代公式：${\theta ^t = \theta ^{t-1} + \Delta \theta}$

  + 将 ${L(\theta ^t)}$ 在 ${\theta ^{t-1}}$ 处进行一阶泰勒展开：${L(\theta ^t)=L(\theta ^{t-1} + \Delta \theta) \approx L(\theta ^{t-1}) + L^\prime(\theta ^{t-1})\Delta \theta}$

  + 要使 ${L(\theta ^t) < L(\theta ^{t-1}) }$，取 ${\Delta \theta = -\alpha L^\prime(\theta ^{t-1})}$

  + 其中  ${\alpha}$ 是步长，可以通过 line search 确定，但一般直接赋一个小的数。

## See Also

  + [[SGD]]


