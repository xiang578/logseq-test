---
title: Transformer/Ref
public: true
tags:
date: 2024-10-05
updated: 2024-10-05
toc: true
mathjax: true
---

TODO [为节约而生：从标准Attention到稀疏Attention - 科学空间|Scientific Spaces](https://spaces.ac.cn/archives/6853)

TODO [有哪些令你印象深刻的魔改transformer？ - 知乎 (zhihu.com)](https://www.zhihu.com/question/349958732)

[The Transformer Family](https://lilianweng.github.io/lil-log/2020/04/07/the-transformer-family.html)

  + Character-level language modeling with deeper self-attention


