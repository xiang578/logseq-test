---
public: true
title: XGBoost/Question
deck: being/Algorithm/XGBoost
tags:
date: 2024-10-05
updated: 2024-10-05
toc: true
mathjax: true
---

如何理解 XGB 的延展性？
  + 基分类器 :-> CART决策树、LR 和 Linear
  + 目标函数 :-> 自定义 loss function，需要二阶可导
  + 学习方法 :-> block 结构支持并行化，支持 out-of-core 计算
GBDT 和 XGboost 的区别
  + 算法本身优化

    + 学习器 :-> 支持更多弱学习器
    + 模型复杂度控制 :-> 损失函数加入正则化控制模型复杂度，代替原来的剪枝方法
    + 损失函数优化 :-> 对误差部分做二阶泰勒展开，更加准确
  + 运行效率优化

    + 特征预处理 :-> 对所有特征值进行排序分组
    + 对于分组特征 :-> 选择合适的分组大小，使用 CPU 缓存进行读取加速将各个分组保存到多个硬盘提高 IO 速度
    + 决策树建立过程 :-> 并行选择，找到合适的子树分裂特征和特征值
  + 算法鲁棒性

    + 缺失值处理 :-> 枚举所有缺失值在当前节点进入哪棵子树
    + 正则 :-> L1 和 L2 正则
XGB 为什么要使用二阶导数？
  + 求解器 :->  减少求解器的设计，其他损失函数泰勒展开之后最终的形式和 mse 不泰勒展开的形式是完全一致的。
  + 通用性 :-> 统一损失函数求导形式，可以自定义损失函数
  + 收敛 :-> 二阶导数能让梯度更快收敛
  + 计算量 :-> 可以使用打分函数，减少分裂子叶时的计算量
如何选择用一种模型来替代 xgboost 模型，你会用什么？



[[机器学习知识体系汇总]] Xgboost

  + 你选择使用xgboost的原因是什么？#card
  + Xgboost和GBDT有什么异同？#card
  + 为什么xgboost训练会那么快，主要优化点事什么？#card
  + Xgboost是如何处理缺失值的？#card
    + 首先忽略带缺失值的数据，像正常情况下一样将前两种数据分别计算并导流到左子树和右子树。


    + 然后计算带缺失值的数据导流向左右子树，计算两种方案下的Objective 情况，取得分最小的作为在这个节点的默认情况。


  + Xgboost和lightGBM有哪些异同？#card
    + 算法本身

    + 运行效率

    + 鲁棒性

  + Xgboost为什么要使用泰勒展开式，解决什么问题？#card
  + Xgboost是如何寻找最优特征的？#card